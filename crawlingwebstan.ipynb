{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from bs4 import BeautifulSoup\n",
    "import re \n",
    "import pysolr\n",
    "import requests \n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "base_url = \"https://www.pknstan.ac.id/\";\n",
    "\n",
    "urlList = []\n",
    "for i in range (0, 70):\n",
    "    req = requests.get(base_url + \"frontpage?page=\" + str(i))\n",
    "    soup = BeautifulSoup(req.text, \"html.parser\")\n",
    "    for a in soup.find_all('a',href=True):\n",
    "        url = a['href']\n",
    "        if (url[0:9] == \"/article/\") :\n",
    "#             print(url)\n",
    "            urlList.append(url)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(len(urlList))\n",
    "# print(urlList)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "result = [] \n",
    "for i in urlList: \n",
    "    if i not in result: \n",
    "        result.append(i) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(len(result))\n",
    "print(result[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def scrap(url) : \n",
    "    req = requests.get(url)\n",
    "    soup = BeautifulSoup(req.text,\"html.parser\")\n",
    "\n",
    "\n",
    "    title = soup.find('h2', {'class':'node-title'}).text\n",
    "       \n",
    "#     dataBody = soup.find('div', {'class' : 'field-item odd'})\n",
    "\n",
    "#     if dataBody is None : \n",
    "#         body = \"tidak ada konten\"\n",
    "#     else :\n",
    "#         body = dataBody.text\n",
    "#         body = ' '.join(re.sub(\"(@[A-Za-z0-9]+)|([^0-9A-Za-z \\t])|(\\w+:\\/\\/\\S+)\",\" \",x).split())\n",
    "\n",
    "    body = \"\"\n",
    "    for p in soup.find_all('p', {'class' : 'rtejustify'}) : \n",
    "        body += p.text\n",
    "    \n",
    "    if body == \"\" :\n",
    "        body = \" \"\n",
    "        for p in soup.find_all('p') : \n",
    "            body += p.text\n",
    "\n",
    "    time = soup.find('div', {'class' : 'time pubdate'})['title']\n",
    "    \n",
    "\n",
    "    uploader = soup.find('span', {'class', 'username'}).text\n",
    "\n",
    "    \n",
    "    return {\"id\": url, \"title_txt_id\":title, \"body_txt_id\":body, \"pdate\" : time, \"uploader_txt_id\":uploader}\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data = []\n",
    "for i in range(len(result)):\n",
    "    data.append(scrap(\"https://www.pknstan.ac.id\" + result[i]))\n",
    "#     print(data)\n",
    "# #     print(result[i])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(len(data))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pysolr\n",
    "solr = pysolr.Solr(\"http://localhost:8983/solr/core_stan/\")\n",
    "solr.ping()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "solr.add(data)\n",
    "solr.commit()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# percobaan untuk membuat fungsi \n",
    "\n",
    "req = requests.get('https://www.pknstan.ac.id/article/halal-bihalal-pkn-stan-tahun-2022')\n",
    "soup = BeautifulSoup(req.text,\"html.parser\")\n",
    "\n",
    "title = soup.find('h2', {'class':'node-title'}).text\n",
    "    # print(title)\n",
    "# body = soup.find('p', {'class' : 'rtejustify'}).text\n",
    "\n",
    "\n",
    "# # print(dataBody)\n",
    "\n",
    "# # if dataBody is None : \n",
    "# #     body = \"tidak ada konten\"\n",
    "# # elif dataBody == \" \":\n",
    "body = \"\"\n",
    "for p in soup.find_all('p', {'class' : 'rtejustify'}) : \n",
    "    body += p.text\n",
    "#     print(p)\n",
    "# else :\n",
    "#     body = dataBody.text\n",
    "    \n",
    "print(body)      \n",
    "    \n",
    "# print(type(body))\n",
    "\n",
    "time = soup.find('div', {'class' : 'time pubdate'})['title']\n",
    "    # print(time)\n",
    "\n",
    "uploader = soup.find('span', {'class', 'username'}).text\n",
    "    # print(uploader)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(scrap('https://www.pknstan.ac.id/article/inspektur-jenderal-kemenkeu-kunjungi-kampus-pkn-stan'))"
   ]
  }
 ],
 "metadata": {
  "language_info": {
   "name": "python"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
